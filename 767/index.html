<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Label-guided Real-time Fusion Network forRGB-T Semantic Segmentation</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="200" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center">Label-guided Real-time Fusion Network forRGB-T Semantic Segmentation</h2><br><h5 style="font-weight:normal" align="center"><autocolor>Zengrong Lin (Sun Yat-sen University), Baihong Lin (University of Electronic Science and Technology of China),* Yulan Guo (Sun Yat-sen University)</autocolor></h5><h5 style="font-weight:normal;" align="center"><a href="http://bmvc2022.mpi-inf.mpg.de/BMVC/" target="_blank" ><I><autocolor>The 34<sup>th</sup> British Machine Vision Conference</autocolor></I></a></h5><div class="cta"><a href="https://github.com/KevinBHLin/" role="button">Code</a><br></div><h2 id="abstract">Abstract</h2>RGB-T semantic segmentation has emerged as a promising solution to handle hard scenes with poor lighting conditions by fusing a pair of RGB and thermal images.  Although various deep-learning-based fusion networks have been proposed with excellent performance, most of them are not suitable for real-time applications due to high computational overhead and latency.  To realize high-accuracy RGB-T real-time semantic segmentation, this paper proposes a novel Label-guided Real-time Fusion Network which fuses multi-level features of RGB and thermal images extracted from double two-pathway lightweight backbones based on the proposed Label-guided Fusion Module (LFM). The proposed LFM realizes efficient multi-modal feature fusion by spatial weighted summation, in which a spatial attention map is generated with the guidance of semantic label in the training phase to accurately indicate the contributions of different modalities. Exhaustive experiments on the MFNet and PST900 datasets demonstrate that the proposed method simultaneously achieves higher speed and accuracy compared with other state-of-the-art methods.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Lin_2023_BMVC,
author    = {Zengrong Lin and Baihong Lin and Yulan Guo},
title     = {Label-guided Real-time Fusion Network forRGB-T Semantic Segmentation},
booktitle = {34th British Machine Vision Conference 2023, {BMVC} 2023, Aberdeen, UK, November 20-24, 2023},
publisher = {BMVA},
year      = {2023},
url       = {https://papers.bmvc2023.org/0767.pdf}
}
</code></pre></div></div><br><br><p><small>Copyright &copy 2023 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2023.mpi-inf.mpg.de" rel="noopener"><autocolor>Imprint</autocolor></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2023.mpi-inf.mpg.de?lang=en" rel="noopener"><autocolor>Data Protection</autocolor></a></small></p></section></div></body></html>