<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>DisCLIP: Open-Vocabulary Referring Expression Generation</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="200" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center">DisCLIP: Open-Vocabulary Referring Expression Generation</h2><br><h5 style="font-weight:normal" align="center"><autocolor>Lior Bracha (Bar Ilan University),* Eitan Shaar (bar Ilan University), Aviv Shamsian (Bar Ilan University), Ethan Fetaya (Bar Ilan University), Gal Chechik (NVIDIA)</autocolor></h5><h5 style="font-weight:normal;" align="center"><a href="http://bmvc2022.mpi-inf.mpg.de/BMVC/" target="_blank" ><I><autocolor>The 34<sup>th</sup> British Machine Vision Conference</autocolor></I></a></h5><div class="cta"><a href="https://papers.bmvc2023.org/0670.pdf" role="button">PDF</a><a href="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0670_video.mp4" role="button">Video</a><a href="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0670_supp.zip" role="button">Supplementary</a><a href="https://github.com/dekelio/disclip-open-vocab-reg" role="button">Code</a><br></div><h2 id="abstract">Abstract</h2>Referring Expressions Generation (REG) aims to produce textual descriptions that unambiguously identifies specific objects within a visual scene. Traditionally, this has been achieved through supervised learning methods, which perform well on specific data distributions but often struggle to generalize to new images and concepts. To address this issue, we present a novel approach for REG, named DisCLIP, short for discriminative CLIP. We build on CLIP, a large-scale visual-semantic model, to guide an LLM to generate a contextual description of a target concept in an image while avoiding other distracting concepts. Notably, this optimization happens at inference time and does not require additional training or tuning of learned parameters. 
We measure the quality of the generated text by evaluating the capability of a receiver model to accurately identify the described object within the scene. To achieve this, we use a frozen zero-shot comprehension module as a critique of our generated referring expressions. We evaluate DisCLIP on multiple referring-expression benchmarks through human evaluation and show that it significantly outperforms previous methods on out-of-domain datasets. Our results highlight the potential of using pre-trained visual-semantic models for generating high-quality contextual descriptions in new visual domains. <br><br><h2>Video</h2><center><iframe height="540" width="960" style="max-width:100%;max-height:100%;" src="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0670_video.mp4" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></center><br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Bracha_2023_BMVC,
author    = {Lior Bracha and Eitan Shaar and Aviv Shamsian and Ethan Fetaya and Gal Chechik},
title     = {DisCLIP: Open-Vocabulary Referring Expression Generation},
booktitle = {34th British Machine Vision Conference 2023, {BMVC} 2023, Aberdeen, UK, November 20-24, 2023},
publisher = {BMVA},
year      = {2023},
url       = {https://papers.bmvc2023.org/0670.pdf}
}
</code></pre></div></div><br><br><p><small>Copyright &copy 2023 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><autocolor>Imprint</autocolor></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><autocolor>Data Protection</autocolor></a></small></p></section></div></body></html>