<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Robust and Efficient Edge-guided Pose Estimation with Resolution-conditioned NeRF</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="200" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center">Robust and Efficient Edge-guided Pose Estimation with Resolution-conditioned NeRF</h2><br><h5 style="font-weight:normal" align="center"><autocolor>Liesbeth Claessens (ETH Zurich),* Fabian Manhardt (Google), Ricardo Martin-Brualla (Google), Roland Siegwart (ETH Zürich, Autonomous Systems Lab), Cesar Cadena Lerma (ETH Zurich), Federico Tombari (Google)</autocolor></h5><h5 style="font-weight:normal;" align="center"><a href="http://bmvc2022.mpi-inf.mpg.de/BMVC/" target="_blank" ><I><autocolor>The 34<sup>th</sup> British Machine Vision Conference</autocolor></I></a></h5><div class="cta"><br></div><h2 id="abstract">Abstract</h2>Monocular 6D pose estimation attempts to obtain the 3D location and rotation of
an object from a single input image. Deep Learning based methods have lead to large improvements in this area, but still require highly realistic 3D CAD models or manual data labeling. Neural Radiance Fields (NeRF) have made significant progress in solving the inverse problem of realistically rendering an object from a novel pose without these requirements. Nevertheless, current methods that try to harness them to extract the object’s pose from a given image using an analysis-by-synthesis approach lack robustness and speed, and require hours of pretraining on the object of interest. We propose a novel pose estimation pipeline that makes NeRF-based analysis-by-synthesis reliable and fast.
Our proposal improves the quality of the optimization by 1) changing the representation of the pose to a decoupled and continuous parameterization, 2) increasing the model’s robustness to changes in scale by means of conditioning it on the used resolution, and 3) developing an edge-based sampling strategy that focuses on shooting rays near image regions with a strong learning signal. These improvements, along with our backbone choice, allow us to estimate the pose with more than 5% higher recall and more than 4 times faster than prior work, while reducing the pretraining time from hours to minutes.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Claessens_2023_BMVC,
author    = {Liesbeth Claessens and Fabian Manhardt and Ricardo Martin-Brualla and Roland Siegwart and Cesar Cadena Lerma and Federico Tombari},
title     = {Robust and Efficient Edge-guided Pose Estimation with Resolution-conditioned NeRF},
booktitle = {34th British Machine Vision Conference 2023, {BMVC} 2023, Aberdeen, UK, November 20-24, 2023},
publisher = {BMVA},
year      = {2023},
url       = {https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0543.pdf}
}
</code></pre></div></div><br><br><p><small>Copyright &copy 2023 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><autocolor>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2023.mpi-inf.mpg.de" rel="noopener"><autocolor>Imprint</autocolor></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2023.mpi-inf.mpg.de?lang=en" rel="noopener"><autocolor>Data Protection</autocolor></a></small></p></section></div></body></html>